<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Youngjin Hong</title>

    <meta name="author" content="Youngjin Hong">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="figures/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Youngjin Hong
                </p>
                <p>
I am a PhD student in the Department of Electical and Computer Engineering from University of Minnesota (UMN), advised by <a href="https://choice.umn.edu/people">Prof. Changhyun Choi</a>. 
My research focuses on learning-based robot policies for robust and general robot tasks. I am especially interested in Vision-Language-Action models or applying Vision-Language Models for task planning.
</p>

<p>
Before joining UMN, I was a research engineer at <a href="https://www.hanwhaaerospace.com/eng/index.do">Hanwha Aerospace</a>, where I developed business proposal for the next-generation Unmanned Ground Vehicle (UGV) technologies as well as UGV simulation. 
I completed my master's and bachelor's degree in Mechanical Engineering at the <a href="https://www.skku.edu/eng/">Sungkyunkwan University (SKKU) </a>, advised by <a href="https://rise.skku.edu/members/">Hyungpil Moon</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:hong0745@umn.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?hl=en&user=k_oI1lAAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/youngjin-hong-robot/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Hongyoungjin">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/YoungjinHong.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="figures/YoungjinHong.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Under Review & Research Ongoing</h2>
                <p>
                  <!-- I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Some papers are <span class="highlight">highlighted</span>. -->
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <a href="figures/LACY/thumbnail.png"><img src='figures/LACY/thumbnail.png' width="160"></a>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://szymanowiczs.github.io/bolt3d">
          <span class="papertitle">LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation</span>
        </a>
        <br>
    <strong>Youngjin Hong*</strong>,
        <a href="https://hjy-u.github.io/">Houjian Yu*</a> (Equal Contribution),
        <a href="https://www.linkedin.com/in/mingen-li-8b8110145/">Mingen Li</a>,
        <a href="https://choice.umn.edu/people">Changhyun Choi</a>
        <br>
        <em>Under review (double-blind)</em>
        <br>
        <p></p>
        <p>
		<!-- By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation. -->
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <a href="figures/Hierarchical_DLO/thumbnail.png"><img src='figures/Hierarchical_DLO/thumbnail.png' width="160"></a>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://szymanowiczs.github.io/bolt3d">
          <span class="papertitle">Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models</span>
        </a>
        <br>
        <a href="https://www.linkedin.com/in/mingen-li-8b8110145/">Mingen Li</a>,
        <a href="https://hjy-u.github.io/">Houjian Yu </a>,
        <a href="https://yixuanhuang98.github.io/">Yixuan Huang</a>,
        <strong>Youngjin Hong</strong>,
        <a href="https://hantao-ye.github.io/">Hantao Ye</a>,
        <a href="https://choice.umn.edu/people">Changhyun Choi</a>
        <br>
        <em>Under review (double-blind)</em>
        <br>
        <p></p>
        <p>
		<!-- By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation. -->
        </p>
      </td>
    </tr>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
                <p>
                  <!-- I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Some papers are <span class="highlight">highlighted</span>. -->
                </p>
              </td>
            </tr>
          </tbody></table>


    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <a href="figures/eccomas/thumbnail.png"><img src='figures/eccomas/thumbnail.png' width="160"></a>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://sites.google.com/view/youngjincv/research/vision-based-stable-2d-planar-pushing-of-dishware-with-6-dof-manipulator?authuser=0">
          <span class="papertitle">Vision-based Stable 2D Planar Pushing of Dishware with 6-DOF Manipulator</span>
        </a>
        <br>
        <strong>Youngjin Hong</strong>,
        Hong-ryul Jung,
        Sungwon Seo,
        Jeongmin Jeon,
        Jonghyun Kim,
        Hyungpil Moon
        <br>
        <em>ECCOMAS, 2023</em>
        <br>
        <p></p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <a href="figures/iccas/thumbnail.png"><img src='figures/iccas/thumbnail.png' width="160"></a>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://sites.google.com/view/youngjincv/research/transformable-fingertip-to-augment-tableware-grasp-capability?authuser=0">
          <span class="papertitle">Passive Transformable Fingertip to Augment Tableware Grasp Capability</span>
        </a>
        <br>
        Haejoon Seong*,
        <strong>Youngjin Hong*</strong>,
        Hong-ryul Jung*,
        Myeongyun Doh* (Equal Contribution),
        Jonghyun Kim,
        Hyungpil Moon
        <br>
        <em>ICCAS, 2022</em>
        <br>
        <p></p>
      </td>
    </tr>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Talks and Presentations</h2>
                <p>
                  <!-- I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Some papers are <span class="highlight">highlighted</span>. -->
                </p>
              </td>
            </tr>
          </tbody></table>


      <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <a href="figures/iros2023/thumbnail.png"><img src='figures/iros2023/thumbnail.png' width="160"></a>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://sites.google.com/view/youngjincv/research/transformable-fingertip-to-augment-tableware-grasp-capability?authuser=0">
          <span class="papertitle">Stable Dishware Pushing via Convolutional Neural Networks </span>
        </a>
        <br>
        <strong>Youngjin Hong*</strong>,
        Sungwon Seo*,
        Hong-ryul Jung* (Equal Contribution),
        Jeongmin Jeon,
        Jonghyun Kim,
        Hyungpil Moon
        <br>
        <em>IROS, 2023 (Poster, Late Breaking Results)</em>
        <br>
        <p></p>
      </td>
    </tr>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Academic Services </h2>
                <p>
                  <strong>Reviewer for</strong> IEEE Robotics and Automation Letters (RA-L), 2025
                </p>
              </td>
            </tr>
          </tbody></table>
          
            

    <!-- <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bolt3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bolt3d.mp4" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/bolt3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://szymanowiczs.github.io/bolt3d">
          <span class="papertitle">LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation</span>
        </a>
        <br>
        <a href="https://szymanowiczs.github.io/">Youngjin Hong</a>,
        <a href="https://jasonyzhang.com">Houjian</a>,
        <a href="https://pratulsrinivasan.github.io">Pratul Srinivasan</a>,
        <a href="https://ruiqigao.github.io">Ruiqi Gao</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>,
        <a href="https://holynski.org">Aleksander Holynski</a>,
        <a href="https://ricardomartinbrualla.com">Ricardo Martin-Brualla</a>,
		<strong>Jonathan T. Barron</strong>,
        <a href="https://henzler.github.io">Philipp Henzler</a>
        <br>
        <em>ICCV</em>, 2025
        <br>
        <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
        /
        <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a>
        <p></p>
        <p>
		By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation.
        </p>
      </td>
    </tr> -->

          
					<!-- <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Micropapers</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=hFlF33JZbA0">Radiance Fields and the Future of Generative Media, 2025</a><br>				  
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a><br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
</a><br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a><br>
				<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a><br>
				<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table> -->
  </body>
</html>
